{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто возьмём семинарский ноутбук и напишем то небольшое число строк, которое требуют. В одном месте только потребовалось в уже реализованной функции указать allow_input_downcast = True. $\\varepsilon$ сделаем побольше, чтобы вначале exploration был нормальным, но будем быстрее уменьшать раз в пять итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: theano==0.7 in /home/gipsokarton/miniconda/envs/py34/lib/python3.4/site-packages\n",
      "Requirement already satisfied: scipy>=0.11 in /home/gipsokarton/miniconda/envs/py34/lib/python3.4/site-packages (from theano==0.7)\n",
      "Requirement already satisfied: numpy>=1.6.2 in /home/gipsokarton/miniconda/envs/py34/lib/python3.4/site-packages (from theano==0.7)\n"
     ]
    }
   ],
   "source": [
    "! /home/gipsokarton/miniconda/envs/py34/bin/pip install theano==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata: ......\n",
      "Solving package specifications: .........\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /home/gipsokarton/miniconda/envs/py34:\n",
      "#\n",
      "pybox2d                   2.3.1post2               py34_0    kne\n"
     ]
    }
   ],
   "source": [
    "! conda install -c https://conda.anaconda.org/kne pybox2d --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS='floatX=float32'\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-29 20:45:00,758] Making new env: LunarLander-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f312cc25860>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE2RJREFUeJzt3X+s3Xd93/Hna3FIKDCcQBoZ21nC6hZF1XCSu5CotEqDaJMsmlOpQ0HTiFiEmRQkUKuuSSetRlv/qNSSDXWKZpoUU7GELEBjWWw0mFTt/iDBAWPsmJRLCbJdJ86aH5ChZXV474/zueZw/eOe++Pce8/Hz4d0dL7fz/fX53N9/Dqf+znfzz2pKiRJ/fkHK10BSdJ4GPCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0aW8AnuSHJU0mmk9w5rutIkk4t47gPPsk5wF8D7wYOA18F3ltVTy75xSRJpzSuHvzVwHRV/U1V/T/gAWDLmK4lSTqFNWM673rg0ND6YeAdp9s5idNpteTe+MZ1ALz00tET6z917kVLcu4f/v1zJ84rjUtVZTHHjyvg55RkK7B1pa6v/v3iL36Qqbd8gD1/+wl27dp2Yn0pzJzz5pu3nSjbtWvbafeXVsK4hmiOABuH1je0shOqantVTVXV1JjqoLPYzTdvW7IwH8XUWz7wE2EvrQbjCvivApuSXJbkNcCtwM4xXUs6rZme9rjYa9dqNpYhmqo6nuRDwBeBc4D7qurAOK4lzTbTe9/zt59Yluvt2rUNbh704rnZ0NfqMbYx+Kr6AvCFcZ1fGsVyh60hr9VkxT5klcZhrrH3cfXqf6IXL60SBry6dKqxd3vVOtsY8OrOuD9YPZ2ZXry0WozlTxXMuxJOdJKkkyx2opN/TVKSOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdWpRfw8+ydPAD4BXgeNVNZXkQuAzwKXA08B7quqFxVVTkjRfS9GD/+Wq2lxVU239TmB3VW0Cdrd1SdIyG8cQzRZgR1veAdwyhmtIkuaw2IAv4M+TPJFkayu7uKqOtuVngIsXeQ1J0gIs9jtZ31lVR5L8NPBIkm8Nb6yqOt3X8bU3hK2n2iZJWrwl+07WJNuAl4EPANdV1dEk64C/qKqfm+NYv5NVkmZZse9kTfK6JG+YWQZ+BdgP7ARua7vdBjy8mApKkhZmwT34JG8FPt9W1wD/rap+L8mbgAeBS4DvMbhN8vk5zmUPXpJmWWwPfsmGaBZVCQNekk6yYkM0kqTVzYCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktSpOQM+yX1JjiXZP1R2YZJHkny7PV/QypPk40mmk+xLcuU4Ky9JOr1RevCfBG6YVXYnsLuqNgG72zrAjcCm9tgK3LM01ZQkzdecAV9Vfwk8P6t4C7CjLe8Abhkq/1QNfAVYm2TdUlVWkjS6hY7BX1xVR9vyM8DFbXk9cGhov8Ot7CRJtibZk2TPAusgSTqDNYs9QVVVklrAcduB7QALOV6SdGYL7cE/OzP00p6PtfIjwMah/Ta0MknSMltowO8EbmvLtwEPD5W/r91Ncw3w0tBQjiRpGaXqzKMjSe4HrgPeDDwL/C7wZ8CDwCXA94D3VNXzSQL8EYO7bn4IvL+q5hxjd4hGkk5WVVnM8XMG/HIw4CXpZIsNeGeySlKnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnq1JwBn+S+JMeS7B8q25bkSJK97XHT0La7kkwneSrJr46r4pKkMxvlS7d/CXgZ+FRV/Xwr2wa8XFV/MGvfy4H7gauBtwBfAn62ql6d4xp+J6skzTL272Stqr8Enh/xfFuAB6rqlar6LjDNIOwlSctsMWPwH0qyrw3hXNDK1gOHhvY53MpOkmRrkj1J9iyiDpKk01howN8D/GNgM3AU+MP5nqCqtlfVVFVNLbAOkqQzWFDAV9WzVfVqVf0I+AQ/HoY5Amwc2nVDK5MkLbMFBXySdUOrvwbM3GGzE7g1yXlJLgM2AY8vroqSpIVYM9cOSe4HrgPenOQw8LvAdUk2AwU8DXwQoKoOJHkQeBI4Dtwx1x00kqTxmPM2yWWphLdJStJJxn6bpCRpMhnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1Kk5Az7JxiSPJnkyyYEkH27lFyZ5JMm32/MFrTxJPp5kOsm+JFeOuxGSpJON0oM/DvxmVV0OXAPckeRy4E5gd1VtAna3dYAbgU3tsRW4Z8lrLUma05wBX1VHq+prbfkHwEFgPbAF2NF22wHc0pa3AJ+qga8Aa5OsW/KaS5LOaF5j8EkuBa4AHgMurqqjbdMzwMVteT1waOiww61s9rm2JtmTZM886yxJGsHIAZ/k9cBngY9U1feHt1VVATWfC1fV9qqaqqqp+RwnSRrNSAGf5FwG4f7pqvpcK352ZuilPR9r5UeAjUOHb2hlkqRlNMpdNAHuBQ5W1ceGNu0EbmvLtwEPD5W/r91Ncw3w0tBQjiRpmWQwunKGHZJ3An8FfBP4USv+HQbj8A8ClwDfA95TVc+3N4Q/Am4Afgi8v6rOOM6eZF7DO5J0NqiqLOb4OQN+ORjwknSyxQa8M1klqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHVqlC/d3pjk0SRPJjmQ5MOtfFuSI0n2tsdNQ8fclWQ6yVNJfnWcDZAkndooX7q9DlhXVV9L8gbgCeAW4D3Ay1X1B7P2vxy4H7gaeAvwJeBnq+rVM1zD72SVpFnG/p2sVXW0qr7Wln8AHATWn+GQLcADVfVKVX0XmGYQ9pKkZTSvMfgklwJXAI+1og8l2ZfkviQXtLL1wKGhww5z5jcECYCqYs+ela7FyvNnoKWyZtQdk7we+Czwkar6fpJ7gP8AVHv+Q+Bfz+N8W4Gt86uuzganCripqeWvx0o6XcifbT8HLc5IAZ/kXAbh/umq+hxAVT07tP0TwK62egTYOHT4hlb2E6pqO7C9He8YvM7IwBvwzU/zMcpdNAHuBQ5W1ceGytcN7fZrwP62vBO4Ncl5SS4DNgGPL12VJUmjGKUH/wvAvwK+mWRvK/sd4L1JNjMYonka+CBAVR1I8iDwJHAcuONMd9BIo7CXOuDPQfMx522Sy1IJh2jE4EPWJ57IWR9ie/YY5BpY7G2SBrxWjapiMCIoCZbhPvjlcNVVV1FVJx6SpMUb+TbJ5TQ75O3VSdL8rYoe/Fx679n33j5JK2NV9uBPZ9J79nOF+PD2SWubpNVnogJ+ttUc+IvtkRv20tntqquuWvQ5JmKIZlTDH9Qu15DH7GuO49or0S5JK2Mp/59PdA9+Lkvdw18t4WrvXurTUmdM1wE/23wCf7WE+VwMe2myjTNrzqqAn23mBzsTjJMS6qfjRCFpsow7c87qgJ8x6cE+bDV/8CxpYLkyx4DvnEM40uqynB1KA/4sYthLK2OlRgkM+LOUYS+N30oP/xrwctxeGoOVDncw4HUKs+8ukjS61RDsMwx4ndapXqiGvnRqqynYZxjwmheHc6SftBqDfcYoX7p9fpLHk3wjyYEkH23llyV5LMl0ks8keU0rP6+tT7ftl463CVpJ4/47PNJqNQmv91H+2NgrwPVV9XZgM3BDkmuA3wfurqqfAV4Abm/73w680MrvbvvpLGLgq2eT9LqeM+Br4OW2em57FHA98FAr3wHc0pa3tHXa9nfF3+PPavby1YNJfO2O9OeCk5yTZC9wDHgE+A7wYlUdb7scBta35fXAIYC2/SXgTUtZaU2+U4W+/QCtRpMY7DNG+pC1ql4FNidZC3weeNtiL5xkK7AV4JJLLlns6dSBSf1PtNx8I1w+k/6anNddNFX1YpJHgWuBtUnWtF76BuBI2+0IsBE4nGQN8Ebg705xru3AdoCpqanJ/ilKy2jSQ0fLZ5S7aC5qPXeSvBZ4N3AQeBT49bbbbcDDbXlnW6dt/3L5ipSkZTdKD34dsCPJOQzeEB6sql1JngQeSPIfga8D97b97wX+NMk08Dxw6xjqLUmaw5wBX1X7gCtOUf43wNWnKP+/wL9YktpJkhasqy/dliT9mAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnRrlS7fPT/J4km8kOZDko638k0m+m2Rve2xu5Uny8STTSfYluXLcjZAknWyUL91+Bbi+ql5Oci7wv5L8j7btt6rqoVn73whsao93APe0Z0nSMpqzB18DL7fVc9ujznDIFuBT7bivAGuTrFt8VSVJ8zHSGHySc5LsBY4Bj1TVY23T77VhmLuTnNfK1gOHhg4/3MokSctopICvqlerajOwAbg6yc8DdwFvA/4pcCHw2/O5cJKtSfYk2fPcc8/Ns9qSpLnM6y6aqnoReBS4oaqOtmGYV4A/Aa5uux0BNg4dtqGVzT7X9qqaqqqpiy66aGG1lySd1ih30VyUZG1bfi3wbuBbM+PqSQLcAuxvh+wE3tfuprkGeKmqjo6l9pKk0xrlLpp1wI4k5zB4Q3iwqnYl+XKSi4AAe4F/0/b/AnATMA38EHj/0ldbkjSXOQO+qvYBV5yi/PrT7F/AHYuvmiRpMZzJKkmdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHVq5IBPck6SryfZ1dYvS/JYkukkn0nymlZ+XlufbtsvHU/VJUlnMp8e/IeBg0Prvw/cXVU/A7wA3N7KbwdeaOV3t/0kSctspIBPsgH4Z8Aft/UA1wMPtV12ALe05S1tnbb9XW1/SdIyWjPifv8J+LfAG9r6m4AXq+p4Wz8MrG/L64FDAFV1PMlLbf//PXzCJFuBrW31lST7F9SC1e/NzGp7J3ptF/TbNts1Wf5Rkq1VtX2hJ5gz4JPcDByrqieSXLfQC83WKr29XWNPVU0t1blXk17b1mu7oN+22a7Jk2QPLScXYpQe/C8A/zzJTcD5wD8E/jOwNsma1ovfABxp+x8BNgKHk6wB3gj83UIrKElamDnH4KvqrqraUFWXArcCX66qfwk8Cvx62+024OG2vLOt07Z/uapqSWstSZrTYu6D/23gN5JMMxhjv7eV3wu8qZX/BnDnCOda8K8gE6DXtvXaLui3bbZr8iyqbbFzLUl9ciarJHVqxQM+yQ1JnmozX0cZzllVktyX5NjwbZ5JLkzySJJvt+cLWnmSfLy1dV+SK1eu5meWZGOSR5M8meRAkg+38oluW5Lzkzye5ButXR9t5V3MzO51xnmSp5N8M8nedmfJxL8WAZKsTfJQkm8lOZjk2qVs14oGfJJzgP8C3AhcDrw3yeUrWacF+CRww6yyO4HdVbUJ2M2PP4e4EdjUHluBe5apjgtxHPjNqrocuAa4o/3bTHrbXgGur6q3A5uBG5JcQz8zs3uecf7LVbV56JbISX8twuCOxP9ZVW8D3s7g327p2lVVK/YArgW+OLR+F3DXStZpge24FNg/tP4UsK4trwOeasv/FXjvqfZb7Q8Gd0m9u6e2AT8FfA14B4OJMmta+YnXJfBF4Nq2vKbtl5Wu+2nas6EFwvXALiA9tKvV8WngzbPKJvq1yOAW8u/O/rkvZbtWeojmxKzXZnhG7CS7uKqOtuVngIvb8kS2t/36fgXwGB20rQ1j7AWOAY8A32HEmdnAzMzs1WhmxvmP2vrIM85Z3e0CKODPkzzRZsHD5L8WLwOeA/6kDav9cZLXsYTtWumA714N3mon9lalJK8HPgt8pKq+P7xtUttWVa9W1WYGPd6rgbetcJUWLUMzzle6LmPyzqq6ksEwxR1Jfml444S+FtcAVwL3VNUVwP9h1m3li23XSgf8zKzXGcMzYifZs0nWAbTnY618otqb5FwG4f7pqvpcK+6ibQBV9SKDCXvX0mZmt02nmpnNKp+ZPTPj/GngAQbDNCdmnLd9JrFdAFTVkfZ8DPg8gzfmSX8tHgYOV9Vjbf0hBoG/ZO1a6YD/KrCpfdL/GgYzZXeucJ2WwvBs3tmzfN/XPg2/Bnhp6FexVSVJGExaO1hVHxvaNNFtS3JRkrVt+bUMPlc4yITPzK6OZ5wneV2SN8wsA78C7GfCX4tV9QxwKMnPtaJ3AU+ylO1aBR803AT8NYNx0H+30vVZQP3vB44Cf8/gHfl2BmOZu4FvA18CLmz7hsFdQ98BvglMrXT9z9CudzL41XAfsLc9bpr0tgH/BPh6a9d+4N+38rcCjwPTwH8Hzmvl57f16bb9rSvdhhHaeB2wq5d2tTZ8oz0OzOTEpL8WW103A3va6/HPgAuWsl3OZJWkTq30EI0kaUwMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOvX/ARov22q8TB3IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f312cd9bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "#create input variables. We'll support multiple states at once\n",
    "\n",
    "\n",
    "current_states = T.matrix(\"states[batch,units]\")\n",
    "actions = T.ivector(\"action_ids[batch]\")\n",
    "rewards = T.vector(\"rewards[batch]\")\n",
    "next_states = T.matrix(\"next states[batch,units]\")\n",
    "is_end = T.ivector(\"vector[batch] where 1 means that session just ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#input layer\n",
    "l_states = InputLayer((None,)+state_dim)\n",
    "\n",
    "\n",
    "#<Your architecture. Please start with a single-layer network>\n",
    "l_hidden = DenseLayer(l_states, 100)\n",
    "\n",
    "#output layer\n",
    "l_qvalues = DenseLayer(l_hidden, num_units=n_actions,nonlinearity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get q-values for ALL actions in current_states\n",
    "predicted_qvalues = get_output(l_qvalues,{l_states:current_states})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling agent's \"GetQValues\" function\n",
    "get_qvalues = theano.function([current_states], predicted_qvalues, allow_input_downcast=True)\n",
    "#<compile a function that takes current_states and returns predicted_qvalues>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select q-values for chosen actions\n",
    "predicted_qvalues_for_actions = predicted_qvalues[T.arange(actions.shape[0]),actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict q-values for next states\n",
    "predicted_next_qvalues = get_output(l_qvalues,{l_states:next_states})\n",
    "\n",
    "\n",
    "#Computing target q-values under \n",
    "gamma = 0.99\n",
    "target_qvalues_for_actions = rewards + gamma * predicted_next_qvalues.max(axis=1)\n",
    "\n",
    "#zero-out q-values at the end\n",
    "target_qvalues_for_actions = (1-is_end)*target_qvalues_for_actions\n",
    "\n",
    "#don't compute gradient over target q-values (consider constant)\n",
    "target_qvalues_for_actions = theano.gradient.disconnected_grad(target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean squared error loss function\n",
    "loss = ((target_qvalues_for_actions - predicted_qvalues_for_actions)**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all network weights\n",
    "all_weights = get_all_params(l_qvalues,trainable=True)\n",
    "\n",
    "#network updates. Note the small learning rate (for stability)\n",
    "updates = lasagne.updates.sgd(loss,all_weights,learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function that resembles agent.update(state,action,reward,next_state) \n",
    "#with 1 more argument meaning is_end\n",
    "train_step = theano.function([current_states,actions,rewards,next_states,is_end],\n",
    "                             updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.7 #initial epsilon\n",
    "\n",
    "def generate_session(t_max=1000):\n",
    "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
    "    \n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #get action q-values from the network\n",
    "        q_values = get_qvalues([s])[0] \n",
    "        \n",
    "        a = q_values.argmax()\n",
    "        if np.random.random() < epsilon:\n",
    "            a = np.random.randint(0, n_actions)\n",
    "        #a = <sample action with epsilon-greedy strategy>\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #train agent one step. Note that we use one-element arrays instead of scalars \n",
    "        #because that's what function accepts.\n",
    "        train_step([s],[a],[r],[new_s],[done])\n",
    "        \n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward:-236.754\tepsilon:0.70000\n",
      "mean reward:-211.452\tepsilon:0.70000\n",
      "mean reward:-223.412\tepsilon:0.70000\n",
      "mean reward:-217.201\tepsilon:0.70000\n",
      "mean reward:-177.073\tepsilon:0.42000\n",
      "mean reward:-227.835\tepsilon:0.42000\n",
      "mean reward:-231.992\tepsilon:0.42000\n",
      "mean reward:-196.155\tepsilon:0.42000\n",
      "mean reward:-159.974\tepsilon:0.42000\n",
      "mean reward:-126.837\tepsilon:0.25200\n",
      "mean reward:-125.167\tepsilon:0.25200\n",
      "mean reward:-122.763\tepsilon:0.25200\n",
      "mean reward:-72.183\tepsilon:0.25200\n",
      "mean reward:-40.103\tepsilon:0.25200\n",
      "mean reward:-46.813\tepsilon:0.15120\n",
      "mean reward:-81.194\tepsilon:0.15120\n",
      "mean reward:-115.417\tepsilon:0.15120\n",
      "mean reward:-137.747\tepsilon:0.15120\n",
      "mean reward:-55.413\tepsilon:0.15120\n",
      "mean reward:-53.032\tepsilon:0.09072\n",
      "mean reward:-30.231\tepsilon:0.09072\n",
      "mean reward:13.222\tepsilon:0.09072\n",
      "mean reward:-1.473\tepsilon:0.09072\n",
      "mean reward:49.774\tepsilon:0.09072\n",
      "mean reward:37.517\tepsilon:0.05443\n",
      "mean reward:39.622\tepsilon:0.05443\n",
      "mean reward:90.634\tepsilon:0.05443\n",
      "mean reward:7.162\tepsilon:0.05443\n",
      "mean reward:-20.764\tepsilon:0.05443\n"
     ]
    }
   ],
   "source": [
    "for i in range(29):\n",
    "    \n",
    "    rewards = [generate_session() for _ in range(100)] #generate new sessions\n",
    "    \n",
    "    if i% 5 == 4:\n",
    "        epsilon*=0.6\n",
    "    \n",
    "    print (\"mean reward:%.3f\\tepsilon:%.5f\"%(np.mean(rewards),epsilon))\n",
    "\n",
    "    if np.mean(rewards) > 300:\n",
    "        print (\"You Win!\")\n",
    "        break\n",
    "        \n",
    "    assert epsilon!=0, \"Please explore environment\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний счёт за последние 5 итераций больше нуля (что, вроде, примерно и требовалось). На этом и остановимся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon=0 #Don't forget to reset epsilon back to initial value if you want to go on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-29 21:16:57,511] Clearing 12 monitor files from previous run (because force=True was provided)\n",
      "[2018-01-29 21:16:57,630] Starting new video recorder writing to /home/gipsokarton/mipt_ml_dz/videos/openaigym.video.2.5690.video000000.mp4\n",
      "[2018-01-29 21:17:11,122] Starting new video recorder writing to /home/gipsokarton/mipt_ml_dz/videos/openaigym.video.2.5690.video000001.mp4\n",
      "[2018-01-29 21:17:16,175] Starting new video recorder writing to /home/gipsokarton/mipt_ml_dz/videos/openaigym.video.2.5690.video000008.mp4\n",
      "[2018-01-29 21:17:50,051] Starting new video recorder writing to /home/gipsokarton/mipt_ml_dz/videos/openaigym.video.2.5690.video000027.mp4\n",
      "[2018-01-29 21:18:21,456] Starting new video recorder writing to /home/gipsokarton/mipt_ml_dz/videos/openaigym.video.2.5690.video000064.mp4\n",
      "[2018-01-29 21:18:59,988] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/gipsokarton/mipt_ml_dz/videos')\n"
     ]
    }
   ],
   "source": [
    "#record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(env,directory=\"videos\",force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "#unwrap \n",
    "env = env.env.env\n",
    "#upload to gym\n",
    "#gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later\n",
    "\n",
    "#Warning! If you keep seeing error that reads something like\"DoubleWrapError\",\n",
    "#run env=gym.make(\"CartPole-v0\");env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.2.5690.video000027.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
